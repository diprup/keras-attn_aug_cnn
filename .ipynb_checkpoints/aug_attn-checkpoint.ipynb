{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0919 11:42:23.212865  8368 deprecation_wrapper.py:119] From T:\\TTS_result\\DC-TTS_bd_en_300k\\speech_out2\\attention_aug_cnn\\keras-attn_aug_cnn\\aug_attn.py:148: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 10)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 10)     310         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 12)     132         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 32, 1, 12)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d (Atten (None, None, None, N 64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 32, 4)        0           attention_augmentation2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 16)     816         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 32, 4)        20          reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 1, 16)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 32, 1, 4)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 1, 20)    0           reshape[0][0]                    \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 32, 20)       0           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,342\n",
      "Trainable params: 1,342\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1, 32, 10)\n",
      "(1, 32, 20)\n"
     ]
    }
   ],
   "source": [
    "# compatible with tensorflow layers\n",
    "\n",
    "from aug_attn import *\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "ip = Input(shape=(None, 10))\n",
    "cnn1 = Conv1D(filters = 10, kernel_size=3, strides=1,padding='same')(ip)\n",
    "x = augmented_conv1d(cnn1, shape = (32, 10), filters=20, kernel_size=5,\n",
    "                     strides = 1,\n",
    "                     padding = 'causal', # if causal convolution is needed\n",
    "                     depth_k=4, depth_v=4,  \n",
    "                     num_heads=4, relative_encodings=True)\n",
    "\n",
    "# depth_k | filters, depth_v | filters,  Nh | depth_k, Nh | filters-depth_v\n",
    "\n",
    "model = Model(ip, x)\n",
    "model.summary()\n",
    "\n",
    "x = tf.ones((1, 32, 10))\n",
    "print(x.shape)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.TensorShape([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 11:42:29.666816  8368 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
    "\n",
    "\n",
    "(train_data, validation_data), test_data = tfds.load(\n",
    "    name=\"definite_pronoun_resolution\", \n",
    "    split=(train_validation_split, tfds.Split.TEST),\n",
    "    as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for cdata in tfds.as_numpy(train_data):\n",
    "    sentences.append(str(cdata[0]))\n",
    "    labels.append(int(cdata[1]))\n",
    "\n",
    "sentences_v = []\n",
    "labels_v = []\n",
    "\n",
    "for cdata in tfds.as_numpy(validation_data):\n",
    "    sentences_v.append(str(cdata[0]))\n",
    "    labels_v.append(int(cdata[1]))\n",
    "    \n",
    "sentences_t = []\n",
    "labels_t = []\n",
    "\n",
    "for cdata in tfds.as_numpy(test_data):\n",
    "    sentences_t.append(str(cdata[0]))\n",
    "    labels_t.append(int(cdata[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n",
      "802\n",
      "520\n",
      "520\n",
      "564\n",
      "564\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(labels))\n",
    "\n",
    "print(len(sentences_v))\n",
    "print(len(labels_v))\n",
    "\n",
    "print(len(sentences_t))\n",
    "print(len(labels_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "X_token = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(sentences_v)\n",
    "\n",
    "X_token_v = tokenizer.texts_to_sequences(sentences_v)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "tokenizer.fit_on_texts(sentences_t)\n",
    "\n",
    "X_token_t = tokenizer.texts_to_sequences(sentences_t)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336\n",
      "36\n",
      "35\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "print(max([len(a) for a in X_token]))\n",
    "print(max([len(a) for a in X_token_v]))\n",
    "print(max([len(a) for a in X_token_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 36\n",
    "X_pad = pad_sequences(X_token, padding='post', maxlen=maxlen)\n",
    "X_pad_v = pad_sequences(X_token_v, padding='post', maxlen=maxlen)\n",
    "X_pad_t = pad_sequences(X_token_t, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(802, 36, 1)\n",
      "(802,)\n",
      "(520, 36, 1)\n",
      "(520,)\n",
      "(564, 36, 1)\n",
      "(564,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_in = np.reshape(X_pad, (802, 36, 1))\n",
    "y_out = np.array(labels)\n",
    "\n",
    "X_in_v = np.reshape(X_pad_v, (520, 36, 1))\n",
    "y_out_v = np.array(labels_v)\n",
    "\n",
    "X_in_t = np.reshape(X_pad_t, (564, 36, 1))\n",
    "y_out_t = np.array(labels_t)\n",
    "\n",
    "print(X_in.shape)\n",
    "print(y_out.shape)\n",
    "\n",
    "print(X_in_v.shape)\n",
    "print(y_out_v.shape)\n",
    "\n",
    "print(X_in_t.shape)\n",
    "print(y_out_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Conv Layers, (sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 36, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 36, 5)             40        \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 36, 5)             180       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from aug_attn import *\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ip = Input(shape=(36, 1))\n",
    "cnn1 = Conv1D(filters = 5, kernel_size=7, strides=1,padding='same', activation = 'relu')(ip)\n",
    "cnn2 = Conv1D(filters = 5, kernel_size=7, strides=1,padding='same', activation = 'relu')(cnn1)\n",
    "fl = Flatten()(cnn2)\n",
    "fc = Dense(1, activation='sigmoid')(fl)\n",
    "\n",
    "basic_cnn = Model(ip, fc)\n",
    "\n",
    "basic_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "basic_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 802 samples, validate on 520 samples\n",
      "Epoch 1/10\n",
      "802/802 [==============================] - ETA: 3s - loss: 5.7500 - acc: 0.625 - ETA: 0s - loss: 7.6735 - acc: 0.496 - 0s 370us/sample - loss: 7.4991 - acc: 0.5087 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 2/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 11.4999 - acc: 0.25 - ETA: 0s - loss: 7.7230 - acc: 0.4963 - 0s 136us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 3/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 4.7916 - acc: 0.687 - ETA: 0s - loss: 7.3928 - acc: 0.517 - 0s 136us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 4/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 7.6666 - acc: 0.500 - ETA: 0s - loss: 7.4594 - acc: 0.513 - 0s 136us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 5/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 4.7916 - acc: 0.687 - ETA: 0s - loss: 7.6162 - acc: 0.503 - 0s 117us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 6/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 5.7500 - acc: 0.625 - ETA: 0s - loss: 7.3892 - acc: 0.518 - 0s 117us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 7/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 11.4999 - acc: 0.25 - ETA: 0s - loss: 7.5192 - acc: 0.5096 - 0s 117us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 8/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 6.7083 - acc: 0.562 - ETA: 0s - loss: 7.7171 - acc: 0.496 - 0s 136us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 9/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 7.6666 - acc: 0.500 - ETA: 0s - loss: 7.1370 - acc: 0.534 - 0s 117us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n",
      "Epoch 10/10\n",
      "802/802 [==============================] - ETA: 0s - loss: 8.6249 - acc: 0.437 - ETA: 0s - loss: 7.3717 - acc: 0.519 - 0s 117us/sample - loss: 7.5519 - acc: 0.5075 - val_loss: 7.8435 - val_acc: 0.4885\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = basic_cnn.fit(X_in, y_out, epochs = 10, batch_size = 16, validation_data = (X_in_v, y_out_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 36, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 36, 12)       24          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 32, 1, 12)    0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_3 (Att (None, None, None, N 64          reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 32, 4)        0           attention_augmentation2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 36, 16)       64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 32, 4)        20          reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 32, 1, 16)    0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 32, 1, 4)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 1, 20)    0           reshape_15[0][0]                 \n",
      "                                                                 reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 32, 20)       0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 20)       0           reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 640)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            641         flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 813\n",
      "Trainable params: 813\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip = Input(shape=(36, 1))\n",
    "x = augmented_conv1d(ip, shape = (32, 1), filters=20, kernel_size=3,\n",
    "                     strides = 1,\n",
    "                     padding = 'same', # if causal convolution is needed\n",
    "                     depth_k=4, depth_v=4,  \n",
    "                     num_heads=4, relative_encodings=True)\n",
    "cnn2 = Activation('relu')(x)\n",
    "fl = Flatten()(cnn2)\n",
    "fc = Dense(1, activation='sigmoid')(fl)\n",
    "\n",
    "basic_cnn = Model(ip, fc)\n",
    "\n",
    "basic_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "basic_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 32, 32, 10)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 10)   910         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   132         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_14 (At (None, 32, 32, 4)    126         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   4016        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 4)    20          attention_augmentation2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 20)   0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,204\n",
      "Trainable params: 5,204\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1, 32, 32, 10)\n",
      "(1, 32, 32, 20)\n"
     ]
    }
   ],
   "source": [
    "from aug_attn import *\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "ip = Input(shape=(32, 32, 10))\n",
    "cnn1 = Conv2D(filters = 10, kernel_size=3, strides=1,padding='same')(ip)\n",
    "x = augmented_conv2d(cnn1, filters=20, kernel_size=5, # shape parameter is not needed\n",
    "                     strides = 1,\n",
    "                     depth_k=4, depth_v=4,  # padding is by default, same\n",
    "                     num_heads=4, relative_encodings=True)\n",
    "\n",
    "# depth_k | filters, depth_v | filters,  Nh | depth_k, Nh | filters-depth_v\n",
    "\n",
    "model = Model(ip, x)\n",
    "model.summary()\n",
    "\n",
    "x = tf.ones((1, 32, 32, 10))\n",
    "print(x.shape)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu_training",
   "language": "python",
   "name": "cpu_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
